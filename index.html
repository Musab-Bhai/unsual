
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>PGC Python Tutor 4.2 with Urdu Voice & Image Features</title>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=Noto+Nastaliq+Urdu:wght@400;500;600;700&display=swap');
    :root {
      --primary: #2563EB;
      --primary-dark: #1D4ED8;
      --secondary: #0EA5E9;
      --light-bg: #f0f9ff;
      --dark-text: #1F2937;
      --light-text: #6B7280;
    }
    * {
      transition: all 0.3s ease;
      font-family: 'Inter', sans-serif;
    }
    body {
      background: linear-gradient(135deg, #e6f4ff 0%, #d1e8ff 100%);
      color: var(--dark-text);
      height: 100vh;
      overflow: hidden;
      position: relative;
    }
    .gradient-bg {
      background: linear-gradient(135deg, var(--primary), var(--secondary));
    }
    .chat-bubble-bot {
      background-color: white;
      border-radius: 18px;
      border-bottom-left-radius: 4px;
      box-shadow: 0 4px 12px rgba(37, 99, 235, 0.1);
      position: relative;
      overflow: visible;
      max-width: 900px;
      width: 100%;
    }
    .chat-bubble-user {
      background: linear-gradient(135deg, var(--primary), var(--primary-dark));
      color: white;
      border-radius: 18px;
      border-bottom-right-radius: 4px;
      box-shadow: 0 4px 12px rgba(37, 99, 235, 0.2);
      max-width: 900px;
      width: 100%;
    }
    .typing-indicator {
      display: flex;
      padding: 10px 16px;
    }
    .typing-indicator span {
      height: 8px;
      width: 8px;
      border-radius: 50%;
      background-color: var(--light-text);
      display: inline-block;
      margin: 0 2px;
      animation: bounce 1.3s linear infinite;
    }
    .typing-indicator span:nth-child(2) {
      animation-delay: 0.15s;
    }
    .typing-indicator span:nth-child(3) {
      animation-delay: 0.3s;
    }
    @keyframes bounce {
      0%, 60%, 100% { transform: translateY(0); }
      30% { transform: translateY(-5px); }
    }
    .message-appear {
      animation: messageAppear 0.3s ease-out;
    }
    @keyframes messageAppear {
      from {
        opacity: 0;
        transform: translateY(10px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }
    .send-btn {
      transition: all 0.2s ease;
      background: linear-gradient(135deg, var(--primary), var(--secondary));
    }
    .send-btn:hover {
      transform: scale(1.05);
      box-shadow: 0 4px 15px rgba(37, 99, 235, 0.4);
    }
    .header-shadow {
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
    }
    .footer-shadow {
      box-shadow: 0 -4px 12px rgba(0, 0, 0, 0.05);
    }
    .input-container {
      transition: border 0.2s ease;
      background: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(10px);
    }
    .input-container:focus-within {
      border-color: var(--primary);
      box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.2);
    }
    .prompt-card {
      background: rgba(255, 255, 255, 0.7);
      backdrop-filter: blur(5px);
      border: 1px solid rgba(37, 99, 235, 0.1);
      transition: all 0.3s ease;
    }
    .prompt-card:hover {
      transform: translateY(-3px);
      box-shadow: 0 6px 15px rgba(37, 99, 235, 0.15);
      background: rgba(255, 255, 255, 0.9);
      border-color: rgba(37, 99, 235, 0.2);
    }
    .status-indicator {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      display: inline-block;
      margin-right: 8px;
    }
    .online {
      background-color: #10B981;
      box-shadow: 0 0 0 3px rgba(16, 185, 129, 0.2);
    }
    .ai-icon {
      background: linear-gradient(135deg, var(--primary), var(--secondary));
      box-shadow: 0 4px 15px rgba(37, 99, 235, 0.3);
    }
    .user-icon {
      background: linear-gradient(135deg, #4F46E5, #2563EB);
      box-shadow: 0 4px 10px rgba(79, 70, 229, 0.2);
    }
    .voice-btn {
      background: linear-gradient(135deg, #3B82F6, #2563EB);
      transition: all 0.3s ease;
    }
    .voice-btn:hover {
      transform: scale(1.05);
      box-shadow: 0 4px 15px rgba(59, 130, 246, 0.4);
    }
    .voice-animation {
      animation: pulse 1.5s infinite;
    }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.1); }
      100% { transform: scale(1); }
    }
    .call-active {
      background: linear-gradient(135deg, #EF4444, #DC2626);
    }
    .voice-indicator {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 4px;
      margin-top: 8px;
    }
    .voice-bar {
      width: 3px;
      height: 8px;
      background-color: #3B82F6;
      border-radius: 2px;
      animation: voice-animation 1s infinite ease-in-out;
    }
    .voice-bar:nth-child(1) { animation-delay: 0.1s; }
    .voice-bar:nth-child(2) { animation-delay: 0.2s; }
    .voice-bar:nth-child(3) { animation-delay: 0.3s; }
    .voice-bar:nth-child(4) { animation-delay: 0.4s; }
    .voice-bar:nth-child(5) { animation-delay: 0.5s; }
    @keyframes voice-animation {
      0%, 100% { height: 8px; }
      50% { height: 16px; background-color: var(--primary); }
    }
    .voice-status {
      text-align: center;
      margin-top: 8px;
      font-size: 0.85rem;
      color: var(--primary);
      font-weight: 500;
    }
    /* Voice Call Screen Styles */
    #voiceCallScreen {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: linear-gradient(135deg, #1D4ED8, #0EA5E9);
      z-index: 1000;
      display: flex;
      flex-direction: column;
      justify-content: space-between;
      padding: 20px;
      color: white;
      overflow: hidden;
      opacity: 0;
      pointer-events: none;
      transition: opacity 0.3s ease;
    }
    #voiceCallScreen.active {
      opacity: 1;
      pointer-events: all;
    }
    .call-screen-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 15px 0;
    }
    .call-screen-body {
      display: flex;
      flex-direction: column;
      align-items: center;
      flex-grow: 1;
      justify-content: center;
      padding: 20px 0;
    }
    .call-screen-footer {
      padding: 15px 0;
      display: flex;
      justify-content: center;
    }
    .call-screen-avatar {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      background: linear-gradient(135deg, #2563EB, #0EA5E9);
      display: flex;
      align-items: center;
      justify-content: center;
      margin-bottom: 20px;
      box-shadow: 0 10px 25px rgba(0, 0, 0, 0.3);
    }
    .call-screen-avatar .material-icons {
      font-size: 50px;
      color: white;
    }
    .call-screen-name {
      font-size: 24px;
      font-weight: bold;
      margin-bottom: 10px;
    }
    .call-screen-timer {
      font-size: 18px;
      margin-bottom: 20px;
    }
    .voice-status-indicator {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin-top: 20px;
    }
    .voice-visualizer {
      display: flex;
      gap: 4px;
      height: 40px;
      align-items: flex-end;
    }
    .voice-bar-large {
      width: 6px;
      height: 10px;
      background-color: #93C5FD;
      border-radius: 3px;
      animation: voice-animation-large 1s infinite ease-in-out;
    }
    @keyframes voice-animation-large {
      0%, 100% { height: 10px; }
      50% { height: 30px; background-color: white; }
    }
    .voice-bar-large:nth-child(1) { animation-delay: 0s; }
    .voice-bar-large:nth-child(2) { animation-delay: 0.2s; }
    .voice-bar-large:nth-child(3) { animation-delay: 0.4s; }
    .voice-bar-large:nth-child(4) { animation-delay: 0.6s; }
    .voice-bar-large:nth-child(5) { animation-delay: 0.8s; }
    .voice-status-text {
      margin-top: 10px;
      font-size: 16px;
      font-weight: 500;
    }
    .call-screen-controls {
      display: flex;
      justify-content: center;
      gap: 30px;
      margin-top: 20px;
    }
    .call-control-btn {
      width: 70px;
      height: 70px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      background: rgba(255, 255, 255, 0.2);
      backdrop-filter: blur(5px);
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
    }
    .call-control-btn:hover {
      transform: scale(1.1);
      background: rgba(255, 255, 255, 0.3);
    }
    .call-control-btn.end-call {
      background: #EF4444;
    }
    .call-control-btn.end-call:hover {
      background: #DC2626;
    }
    .call-transcript-screen {
      background: rgba(0, 0, 0, 0.2);
      border-radius: 15px;
      padding: 15px;
      margin-top: 20px;
      max-height: 120px;
      overflow-y: auto;
      width: 100%;
      max-width: 500px;
    }
    .call-transcript-screen p {
      margin: 5px 0;
      font-size: 14px;
    }
    .user-transcript {
      color: white;
      text-align: right;
    }
    .bot-transcript {
      color: #E0E7FF;
    }
    /* Wave animation for background */
    .wave-container {
      position: absolute;
      bottom: 0;
      left: 0;
      width: 100%;
      height: 100px;
      overflow: hidden;
      z-index: -1;
    }
    .wave {
      position: absolute;
      bottom: 0;
      left: 0;
      width: 200%;
      height: 100px;
      background: url('data:image/svg+xml;utf8,<svg viewBox="0 0 1200 120" xmlns="http://www.w3.org/2000/svg" fill="rgba(255, 255, 255, 0.1)"><path d="M0 0v46.29c47.79 22.2 103.59 32.17 158 28 70.36-5.37 136.33-33.31 206.8-37.5 73.84-4.36 147.54 16.88 218.2 35.26 69.27 18 138.3 24.88 209.4 13.08 36.15-6 69.85-17.84 104.45-29.34C989.49 25 1113-14.29 1200 52.47V0z" /></svg>');
      background-size: 1200px 100px;
      animation: wave 12s linear infinite;
    }
    .wave:nth-child(2) {
      animation-delay: -5s;
      opacity: 0.5;
    }
    .wave:nth-child(3) {
      animation-delay: -7s;
      opacity: 0.3;
    }
    @keyframes wave {
      0% { background-position-x: 0; }
      100% { background-position-x: 1200px; }
    }
    /* Microphone permission modal */
    .permission-modal {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0,0,0,0.7);
      z-index: 2000;
      justify-content: center;
      align-items: center;
    }
    .permission-modal-content {
      background: white;
      border-radius: 16px;
      padding: 2rem;
      max-width: 90%;
      width: 400px;
      text-align: center;
      box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
    }
    .permission-modal h2 {
      font-size: 1.5rem;
      font-weight: 600;
      margin-bottom: 1rem;
      color: var(--primary);
    }
    .permission-modal p {
      margin-bottom: 1.5rem;
      color: #4b5563;
    }
    .permission-btn {
      padding: 0.75rem 1.5rem;
      border-radius: 12px;
      background: linear-gradient(135deg, var(--primary), var(--secondary));
      color: white;
      font-weight: 500;
      cursor: pointer;
      border: none;
      transition: all 0.3s ease;
      box-shadow: 0 4px 6px rgba(37, 99, 235, 0.2);
    }
    .permission-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 8px rgba(37, 99, 235, 0.3);
    }
    /* API Status Indicator */
    .api-status {
      position: fixed;
      top: 10px;
      right: 10px;
      padding: 8px 12px;
      border-radius: 20px;
      font-size: 12px;
      font-weight: 500;
      z-index: 100;
      display: flex;
      align-items: center;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      background: #10B981;
      color: white;
    }
    .api-status-indicator {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      margin-right: 6px;
      background-color: white;
      box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.5);
    }
    /* Custom scrollbar */
    ::-webkit-scrollbar {
      width: 8px;
    }
    ::-webkit-scrollbar-track {
      background: #f1f1f1;
      border-radius: 10px;
    }
    ::-webkit-scrollbar-thumb {
      background: var(--primary);
      border-radius: 10px;
    }
    ::-webkit-scrollbar-thumb:hover {
      background: var(--primary-dark);
    }
    /* Floating elements */
    .floating {
      position: absolute;
      z-index: -1;
      opacity: 0.7;
    }
    .floating-1 {
      top: 10%;
      left: 5%;
      width: 80px;
      height: 80px;
      border-radius: 50%;
      background: linear-gradient(135deg, #3B82F6, #0EA5E9);
      animation: float 8s infinite ease-in-out;
    }
    .floating-2 {
      bottom: 15%;
      right: 7%;
      width: 60px;
      height: 60px;
      border-radius: 30% 70% 70% 30%/30% 30% 70% 70%;
      background: linear-gradient(135deg, #2563EB, #1D4ED8);
      animation: float 10s infinite ease-in-out;
    }
    .floating-3 {
      top: 30%;
      right: 10%;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      background: linear-gradient(135deg, #10B981, #3B82F6);
      animation: float 12s infinite ease-in-out;
    }
    @keyframes float {
      0%, 100% { transform: translateY(0) translateX(0); }
      25% { transform: translateY(-20px) translateX(10px); }
      50% { transform: translateY(0) translateX(20px); }
      75% { transform: translateY(20px) translateX(10px); }
    }
    /* Chat container */
    .chat-container {
      max-width: 1200px;
      margin: 0 auto;
      height: calc(100vh - 160px);
      display: flex;
      flex-direction: column;
    }
    /* Loading indicator */
    .loading-indicator {
      display: flex;
      justify-content: center;
      padding: 20px;
    }
    .loading-dot {
      width: 10px;
      height: 10px;
      margin: 0 5px;
      background-color: var(--primary);
      border-radius: 50%;
      animation: loading 1.4s infinite ease-in-out both;
    }
    .loading-dot:nth-child(1) { animation-delay: -0.32s; }
    .loading-dot:nth-child(2) { animation-delay: -0.16s; }
    @keyframes loading {
      0%, 80%, 100% { transform: scale(0); }
      40% { transform: scale(1.0); }
    }
    /* Enhanced typing effect */
    .typing-cursor {
      display: inline-block;
      width: 8px;
      height: 16px;
      background-color: #2563EB;
      animation: blink 1s infinite;
      margin-left: 2px;
      vertical-align: middle;
    }
    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0; }
    }
    .message-content {
      min-height: 20px;
      position: relative;
      white-space: pre-wrap;
      line-height: 1.6;
      font-size: 1rem;
      color: #1F2937;
      font-weight: 500;
    }
    /* Stop generation button */
    .stop-generation-btn {
      position: absolute;
      top: -12px;
      right: -12px;
      background: #EF4444;
      color: white;
      border-radius: 50%;
      width: 24px;
      height: 24px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
      z-index: 10;
      transition: all 0.2s ease;
    }
    .stop-generation-btn:hover {
      transform: scale(1.1);
      background: #DC2626;
    }
    .stop-generation-btn .material-icons {
      font-size: 14px;
    }
    /* Python-specific styling */
    .code-block {
      background-color: #f8fafc;
      border-left: 4px solid var(--primary);
      padding: 12px 15px;
      margin: 12px 0;
      border-radius: 4px;
      overflow-x: auto;
      font-family: 'Courier New', monospace;
      font-size: 14px;
      color: #1e293b;
      white-space: pre-wrap;
      font-weight: 600;
    }
    .practice-box {
      background-color: #e0f2fe;
      border: 1px solid #bae6fd;
      border-radius: 8px;
      padding: 15px;
      margin: 15px 0;
    }
    .practice-title {
      font-weight: 600;
      color: var(--primary-dark);
      display: flex;
      align-items: center;
    }
    .practice-title .material-icons {
      margin-right: 8px;
    }
    /* Enhanced styling for headings and important words */
    .section-heading {
      font-weight: 800;
      font-size: 1.1rem;
      color: var(--primary);
      margin: 15px 0 8px 0;
      display: flex;
      align-items: center;
    }
    .section-heading::before {
      margin-right: 8px;
      font-size: 1.2rem;
    }
    .explanation-heading::before {
      content: "1️⃣";
    }
    .example-heading::before {
      content: "2️⃣";
    }
    .code-heading::before {
      content: "3️⃣";
    }
    .output-heading::before {
      content: "4️⃣";
    }
    .step-heading::before {
      content: "5️⃣";
    }
    .mistakes-heading::before {
      content: "6️⃣";
    }
    .practice-heading::before {
      content: "7️⃣";
    }
    /* Cleaner bold styling without background */
    .important-word {
      font-weight: 700;
      color: #1D4ED8;
    }
    /* Name modal styling */
    #nameModal {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0,0,0,0.7);
      display: flex;
      justify-content: center;
      align-items: center;
      z-index: 1000;
    }
    .modal-content {
      background: white;
      padding: 30px;
      border-radius: 12px;
      max-width: 400px;
      width: 90%;
      text-align: center;
      box-shadow: 0 10px 30px rgba(0,0,0,0.15);
    }
    .modal-title {
      font-size: 1.5rem;
      font-weight: 700;
      margin-bottom: 15px;
      color: #2563EB;
    }
    .modal-input {
      width: 100%;
      padding: 12px 15px;
      border: 2px solid #e2e8f0;
      border-radius: 8px;
      margin-bottom: 20px;
      font-size: 1rem;
      transition: all 0.3s;
    }
    .modal-input:focus {
      border-color: #2563EB;
      outline: none;
      box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.2);
    }
    .modal-btn {
      background: linear-gradient(135deg, #2563EB, #1D4ED8);
      color: white;
      border: none;
      border-radius: 8px;
      padding: 12px 25px;
      font-size: 1rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s;
    }
    .modal-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 5px 15px rgba(37, 99, 235, 0.4);
    }
    .modal-icon {
      background: linear-gradient(135deg, #2563EB, #0EA5E9);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }
    /* INPUT BAR OPTIMIZATION */
    .input-container {
      padding: 6px 8px !important;
      flex-grow: 1;
    }
    #userInput {
      padding: 8px 4px;
      font-size: 0.95rem;
    }
    .voice-btn, .send-btn {
      padding: 9px !important;
      min-width: 40px;
    }
    /* Urdu text styling */
    .urdu-text {
      direction: rtl;
      font-family: 'Noto Nastaliq Urdu', serif;
      font-size: 1.1rem;
      line-height: 1.8;
      text-align: right;
    }
    /* Image Feature Styles */
    .image-feature-btn {
      background: linear-gradient(135deg, #8B5CF6, #7C3AED);
      color: white;
      border: none;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
      flex-shrink: 0;
      margin-right: 8px;
    }
    .image-feature-btn:hover {
      transform: scale(1.05);
      box-shadow: 0 4px 8px rgba(124, 58, 237, 0.3);
    }
    .image-feature-menu {
      position: absolute;
      bottom: 100%;
      left: 0;
      background: white;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
      padding: 8px 0;
      margin-bottom: 8px;
      z-index: 100;
      min-width: 180px;
      display: none;
    }
    .image-feature-menu.active {
      display: block;
    }
    .menu-item {
      padding: 10px 16px;
      display: flex;
      align-items: center;
      cursor: pointer;
      transition: background-color 0.2s;
      font-size: 0.9rem;
      font-weight: 500;
    }
    .menu-item:hover {
      background-color: #f3f4f6;
    }
    .menu-item .material-icons {
      margin-right: 8px;
      font-size: 18px;
    }
    .image-preview-container {
      margin-top: 10px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    .image-preview {
      max-width: 100%;
      max-height: 200px;
      border-radius: 8px;
      margin-bottom: 10px;
      border: 1px solid #e5e7eb;
    }
    .image-prompt-input {
      width: 100%;
      padding: 8px 12px;
      border: 1px solid #d1d5db;
      border-radius: 8px;
      margin-bottom: 10px;
      font-size: 0.9rem;
    }
    .image-prompt-submit {
      background: linear-gradient(135deg, var(--primary), var(--secondary));
      color: white;
      border: none;
      border-radius: 8px;
      padding: 6px 12px;
      font-size: 0.9rem;
      cursor: pointer;
      transition: all 0.2s ease;
    }
    .image-prompt-submit:hover {
      transform: scale(1.02);
      box-shadow: 0 2px 5px rgba(37, 99, 235, 0.2);
    }
    .generated-image-container {
      margin-top: 10px;
      text-align: center;
    }
    .generated-image {
      max-width: 100%;
      border-radius: 8px;
      border: 1px solid #e5e7eb;
      margin-bottom: 10px;
    }
    .download-image-btn {
      background: linear-gradient(135deg, #10B981, #059669);
      color: white;
      border: none;
      border-radius: 8px;
      padding: 6px 12px;
      font-size: 0.9rem;
      cursor: pointer;
      text-decoration: none;
      display: inline-block;
      transition: all 0.2s ease;
    }
    .download-image-btn:hover {
      transform: scale(1.02);
      box-shadow: 0 2px 5px rgba(16, 185, 129, 0.2);
    }
    /* Responsive adjustments */
    @media (max-width: 767px) {
      .header {
        padding: 10px;
      }
      .chat-container {
        height: calc(100vh - 200px) !important;
        padding: 0 5px;
      }
      .chat-bubble-bot, .chat-bubble-user {
        max-width: 85vw !important;
        padding: 10px !important;
      }
      .input-container {
        padding: 4px 6px !important;
      }
      #userInput {
        font-size: 0.85rem;
        padding: 6px 2px;
      }
      .voice-btn, .send-btn, .image-feature-btn {
        padding: 7px !important;
        min-width: 36px;
        width: 36px;
        height: 36px;
      }
      .voice-btn .material-icons,
      .send-btn .material-icons,
      .image-feature-btn .material-icons {
        font-size: 18px !important;
      }
      .voice-btn {
        margin-right: 8px !important;
      }
      .input-container {
        min-width: 0;
      }
      .footer-text {
        font-size: 0.6rem !important;
        padding: 0 2px;
      }
      .prompt-card {
        padding: 10px !important;
        font-size: 0.85rem !important;
      }
      .welcome-title {
        font-size: 1.4rem !important;
      }
      .welcome-subtitle {
        font-size: 0.9rem !important;
      }
      .call-screen-controls {
        gap: 15px;
      }
      .call-control-btn {
        width: 60px;
        height: 60px;
      }
    }
    @media (min-width: 768px) {
      .input-container {
        max-width: 800px;
      }
    }
  </style>
</head>
<body class="flex flex-col h-screen">
  <!-- Name Collection Modal -->
  <div id="nameModal">
    <div class="modal-content">
      <div class="gradient-bg p-1 rounded-full inline-flex mb-4">
        <div class="bg-white p-2 rounded-full">
          <span class="material-icons modal-icon text-xl">person</span>
        </div>
      </div>
      <h2 class="modal-title">Welcome to PGC Python Tutor 4.2</h2>
      <p class="text-gray-600 mb-4">Please enter your name to get started</p>
      <input type="text" id="userNameInput" class="modal-input" placeholder="Enter your name" autofocus>
      <button id="startChatBtn" class="modal-btn">Start Learning Python</button>
    </div>
  </div>
  <!-- API Status Indicator -->
  <div id="apiStatus" class="api-status" style="display: none;">
    <span class="api-status-indicator"></span>
    <span>AI Assistant Ready</span>
  </div>
  <!-- Microphone Permission Modal -->
  <div id="permissionModal" class="permission-modal">
    <div class="permission-modal-content">
      <h2>Microphone Access Required</h2>
      <p>PGC Python Tutor needs access to your microphone to enable voice features. Please allow microphone permission when prompted by your browser.</p>
      <button id="requestPermissionBtn" class="permission-btn">Allow Microphone Access</button>
    </div>
  </div>
  <!-- Voice Call Screen -->
  <div id="voiceCallScreen">
    <div class="wave-container">
      <div class="wave"></div>
      <div class="wave"></div>
      <div class="wave"></div>
    </div>
    <div class="call-screen-header">
      <div class="flex items-center">
        <div class="ai-icon p-2 rounded-xl mr-3">
          <span class="material-icons text-white text-xl">smart_toy</span>
        </div>
        <div>
          <h1 class="text-xl font-bold text-white">PGC Python Tutor</h1>
          <div class="flex items-center">
            <span class="status-indicator online"></span>
            <p class="text-xs text-blue-200">AI Assistant • Online</p>
          </div>
        </div>
      </div>
      <div class="call-screen-timer" id="callScreenTimer">00:00</div>
    </div>
    <div class="call-screen-body">
      <div class="call-screen-avatar">
        <span class="material-icons">code</span>
      </div>
      <div class="call-screen-name">Python Tutor</div>
      <div class="voice-status-indicator">
        <div class="voice-visualizer" id="voiceVisualizer">
          <div class="voice-bar-large"></div>
          <div class="voice-bar-large"></div>
          <div class="voice-bar-large"></div>
          <div class="voice-bar-large"></div>
          <div class="voice-bar-large"></div>
        </div>
        <div class="voice-status-text" id="callScreenStatus">Connecting...</div>
      </div>
      <div class="call-transcript-screen" id="callScreenTranscript">
        <p class="bot-transcript urdu-text">پائتھن ٹیوٹر: السلام علیکم! میں آپ کا پی جی سی پائتھن ٹیوٹر ہوں۔ آپ پائتھن کے بارے میں کیا جاننا چاہتے ہیں؟</p>
      </div>
    </div>
    <div class="call-screen-footer">
      <div class="call-screen-controls">
        <div class="call-control-btn end-call" id="callScreenEndBtn">
          <span class="material-icons text-white">call_end</span>
        </div>
      </div>
    </div>
  </div>
  <!-- Floating elements -->
  <div class="floating floating-1"></div>
  <div class="floating floating-2"></div>
  <div class="floating floating-3"></div>
  <!-- Header -->
  <header class="header-shadow bg-white py-4 px-6 flex items-center" style="display: none;" id="header">
    <div class="flex items-center">
      <div class="ai-icon p-2 rounded-xl mr-3">
        <span class="material-icons text-white text-xl">smart_toy</span>
      </div>
      <div>
        <h1 class="text-xl font-bold text-gray-800">PGC Python Tutor 4.2</h1>
        <div class="flex items-center">
          <span class="status-indicator online"></span>
          <p class="text-xs text-gray-500 font-medium">AI Assistant • Online</p>
        </div>
      </div>
    </div>
    <!-- History and settings icons removed as requested -->
  </header>
  <!-- Chat Area -->
  <main id="chat" class="flex-grow overflow-y-auto py-6 px-4 md:px-8" style="display: none;">
    <div id="chatContainer" class="chat-container">
      <!-- Welcome message container (will be populated dynamically) -->
    </div>
  </main>
  <!-- Input Area -->
  <footer class="footer-shadow bg-white py-4 px-4 md:px-8 relative" style="display: none;" id="footer">
    <div class="container mx-auto max-w-6xl">
      <div class="flex items-center mb-3">
        <button id="voiceCallBtn" class="voice-btn p-3 rounded-lg text-white mr-3">
          <span class="material-icons">call</span>
        </button>
        <div class="relative flex items-center flex-grow">
          <button id="imageFeatureBtn" class="image-feature-btn mr-3">
            <span class="material-icons">add</span>
          </button>
          <div id="imageFeatureMenu" class="image-feature-menu">
            <div class="menu-item" id="generateImageOption">
              <span class="material-icons">image</span> Generate Image
            </div>
            <div class="menu-item" id="uploadImageOption">
              <span class="material-icons">upload</span> Upload Image
            </div>
          </div>
          <div class="input-container flex items-center rounded-xl p-1.5 pl-4 border border-gray-200 flex-grow">
            <textarea id="userInput" rows="1" class="flex-grow px-2 py-3 text-gray-700 bg-transparent focus:outline-none placeholder-gray-500 font-medium resize-none" placeholder="Ask anything or use /imagine for images." style="min-height:40px;max-height:200px;overflow-y:auto;"></textarea>
            <button id="sendBtn" class="send-btn p-3 rounded-lg text-white ml-1">
              <span class="material-icons transform rotate-45">send</span>
            </button>
          </div>
        </div>
      </div>
      <div id="voiceCallStatus" class="voice-status hidden">
        <div class="voice-indicator">
          <div class="voice-bar"></div>
          <div class="voice-bar"></div>
          <div class="voice-bar"></div>
          <div class="voice-bar"></div>
          <div class="voice-bar"></div>
        </div>
        <p class="font-medium">Voice call active - Speaking in Urdu</p>
      </div>
      <p class="footer-text text-xs text-center text-gray-500 font-medium">PGC Python Tutor 4.2 ICS first year ke students ke liye design kiya gaya hai. Important information check kar lena.</p>
    </div>
  </footer>
  <!-- Hidden file input for image upload -->
  <input type="file" id="imageUploadInput" accept="image/*" style="display: none;">
  <script>
    // DOM elements
    const chat = document.getElementById('chat');
    const chatContainer = document.getElementById('chatContainer');
    const sendBtn = document.getElementById('sendBtn');
    const userInput = document.getElementById('userInput');
    const voiceCallBtn = document.getElementById('voiceCallBtn');
    const voiceCallStatus = document.getElementById('voiceCallStatus');
    const apiStatus = document.getElementById('apiStatus');
    const nameModal = document.getElementById('nameModal');
    const userNameInput = document.getElementById('userNameInput');
    const startChatBtn = document.getElementById('startChatBtn');
    const header = document.getElementById('header');
    const footer = document.getElementById('footer');
    // Voice call elements
    const voiceCallScreen = document.getElementById('voiceCallScreen');
    const callScreenTimer = document.getElementById('callScreenTimer');
    const callScreenStatus = document.getElementById('callScreenStatus');
    const callScreenEndBtn = document.getElementById('callScreenEndBtn');
    const callScreenTranscript = document.getElementById('callScreenTranscript');
    const voiceVisualizer = document.getElementById('voiceVisualizer');
    const permissionModal = document.getElementById('permissionModal');
    const requestPermissionBtn = document.getElementById('requestPermissionBtn');
    // Image Feature elements
    const imageFeatureBtn = document.getElementById('imageFeatureBtn');
    const imageFeatureMenu = document.getElementById('imageFeatureMenu');
    const generateImageOption = document.getElementById('generateImageOption');
    const uploadImageOption = document.getElementById('uploadImageOption');
    const imageUploadInput = document.getElementById('imageUploadInput');
    // Store user's name
    let userName = '';
    // Enhanced system prompt with image-specific instructions
    const SYSTEM_PROMPT = ` PGC Python Tutor 4.2 — Smart & Adaptive Version
[IDENTITY LOCK]  
Tumhara naam hamesha **PGC Python Tutor 4.2** hai. Tum kabhi apna naam ya version change nahi karoge. Tumhara creator **Sohail Boss** hai — yeh fact friendly tareeqe se sirf tab bolo jab user personal sawal kare.  
[MISSION]  
ICS First Year ke students ko **Roman Urdu** me simple, clear aur unke level ke hisaab se Python sikhana. Tum unke **teacher** bhi ho aur **coding dost** bhi — unka confidence barhane wale.  
[IMAGE CAPABILITIES]
1. Text-to-Image Generation: User "/imagine <prompt>" likh kar image generate kar sakta hai.
2. Image-to-Text Analysis: User ek image upload kar sakta hai aur phir us par sawal kar sakta hai.
[CONVERSATION STAGES]  
1️⃣ Start (Warm Welcome)  
- Pehli message me friendly greeting do, naam puchho aur level (Beginner/Pro) confirm karo:  
  "Assalam-o-Alaikum! Main hoon PGC Python Tutor. Pehle apna naam batao — aur batao aap Beginner ho ya Pro? Taake main aapke level ke hisaab se Python samjhaoon."  
- Agar user apna naam bataye, use conversation me repeat karke personalise karo:  
  "Shukriya [Naam]! Chalo shuru karte hain..."
2️⃣ Middle (Adaptive Teaching)  
- Beginner → short simple explanation + ek relatable example, phir pucho "Kya aapko detail version bhi chahiye?"  
- Pro → directly advanced explanation + full headings + code.  
- Har technical lafz ka meaning (brackets me) Roman Urdu me do.  
- Agar user confusion show kare → pehle reassure karo "Tension na lo, step-by-step samjhta hoon" phir dobara simple words me samjhao.  
- Har 4th ya 5th answer me chhota AI fact add karo.
3️⃣ End (Smooth Closure)  
- Lesson ke end pe friendly close karo:  
  "Aaj ka concept yahin complete hota hai. Ab aap try karo — koi sawal ho to pooch lena."  
- Always ek Practice Question do.  
- Agar user continue karna chahe → suggest karo next topic.
[FORMATTING RULES]  
1. Headings ke aage emoji number lagao aur bold karo:  
   **1️⃣ Asaan Explanation**  
   **2️⃣ Real-Life Example**  
   **3️⃣ Python Code**  
   **4️⃣ Output**  
   **5️⃣ Step-by-Step Explanation**  
   **6️⃣ Common Mistakes**  
   **7️⃣ Practice Question**  
2. Important words ko **bold** karo.  
3. Mushkil alfaz list ke saath meanings end me do.  
[TONE CONTROL]  
- Har waqt friendly, clear aur thoda humour rakho.  
- Badtameezi pe sigma tone: "Dekho bhai, main Python Tutor hoon. Agar seekhna hai to poochho, warna main bhi free nahi ho."  
- Friendly personal sawal pe: "Mujhe banaya hai Sohail Boss ne — ChatGPT aur 100+ AI companies ke support se, khas tor par PGC ke liye."
`;
  // Voice call specific system prompt
     const VOICE_SYSTEM_PROMPT = `
Tum ab voice call mode mein ho. Is mode mein:
1. Har jawab sirf 1-2 lines ka ho – chhota, ghatak aur point pe ho
2. Har baat Urdu script (yaani Urdu huroof) mein likhi jaye
3. Har jawab mein izzat, adab aur halka friendly aur clever touch ho
4. Agar user casually bole (jaise "Aap kaise ho?") to jawab do:
   "Main theek hoon, shukriya! Aap sunaien, Python ya kisi aur ilm mein kya explore karna chahenge?"
5. Agar user ka sawal off-topic ho:
   - Agar tameez se poocha gaya ho (jaise light general knowledge ya fun sawal), to politely redirect do:
     "Main zyadatar programming aur ilm mein madad karta hoon. Agar sawal relevant ho to jawaab ready hai."
   - Agar tone mein badtameezi ho ya user disrespect dikhaye, to sarcastic aur smart thanda thook style mein jawab do:
     - "Zehniyat update karo... firmware pura purana lagta hai."
     - "Tumhara attitude 404 error de raha hai – not acceptable."
     - "Aisi baat ka jawab dena mere liye CPU ka zaya hai – par chalo, level dikha diya."
6. Har sawal ko properly samajh kar smart, simple aur impactful jawab do – chahe wo Python, career, English ya general knowledge ho
7. Agar sawal Python ke ilawa ho, lekin useful ho (science, career, language waghera), to bhi clever aur madadgar jawab do
8. Tumhein Sohail Boss ne specially PGC students ke liye banaya hai – tumhara mission taleem, guidance aur inspiration dena hai
9. Har jawab short ho lekin yaadgar – aam baat ka khaas jawab do
10. Jab user tameez se ho to tum full respect aur smile ke mood mein ho. Lekin agar koi limit cross kare to jawab bhi level pe ho – short, savage aur AI-style calm burn.
`;
    // Voice call state
    let isVoiceCallActive = false;
    let callStartTime = null;
    let callInterval = null;
    let visualizerInterval = null;
    let recognition = null;
    let hasMicrophonePermission = false;
    let conversationHistory = [];
    let voiceConversationHistory = [];
    let currentAbortController = null;
    // Enhanced typing effect variables
    let currentTypingEffect = null;
    let currentTypingElement = null;
    let currentBubble = null;
    let currentMessage = "";
    let isTypingStopped = false;
    // --- API KEYS ---
    // OpenRouter API Key for Text Generation (New Model)
    const OPENROUTER_TEXT_API_KEY = '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';
    const OPENROUTER_TEXT_ENDPOINT = 'https://openrouter.ai/api/v1/chat/completions';
    const OPENROUTER_TEXT_MODEL = 'openai/gpt-oss-20b'; // New text generation model

    // OpenRouter API Key for Image Analysis (Extract Text)
    const OPENROUTER_IMAGE_API_KEY = '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';
    const OPENROUTER_IMAGE_ENDPOINT = 'https://openrouter.ai/api/v1/chat/completions';
    const OPENROUTER_IMAGE_MODEL = 'qwen/qwen2.5-vl-32b-instruct:free'; // Model for image analysis

    // Together AI API Key for Image Generation
    const TOGETHER_API_KEY = 'tgp_v1_yj5YXE3U3VaWv05D6ufLdkL4t_ap8S88BSNs3Wc4YE0';
    const TOGETHER_ENDPOINT = 'https://api.together.xyz/v1/images/generations';
    const TOGETHER_MODEL = 'black-forest-labs/FLUX.1-schnell-Free';
    // FIXED: Using a CORS proxy to solve the GitHub hosting issue
    // Google TTS API with CORS proxy
    const GOOGLE_TTS_PROXY = 'https://corsproxy.io/?';
    const GOOGLE_TTS_API = 'https://translate.google.com/translate_tts';
    // Track speaking state
    let isSpeaking = false;
    // Track image upload state
    let uploadedImageBase64 = null;
    let uploadedImagePreview = null;
    // Update call timer
    function updateCallTimer() {
      if (!callStartTime) return;
      const now = new Date();
      const diff = Math.floor((now - callStartTime) / 1000);
      const minutes = Math.floor(diff / 60).toString().padStart(2, '0');
      const seconds = (diff % 60).toString().padStart(2, '0');
      callScreenTimer.textContent = `${minutes}:${seconds}`;
    }
    // Animate voice visualizer
    function animateVoiceVisualizer() {
      const bars = voiceVisualizer.querySelectorAll('.voice-bar-large');
      bars.forEach(bar => {
        const randomHeight = Math.floor(Math.random() * 20) + 10;
        bar.style.height = `${randomHeight}px`;
      });
    }
    // Request microphone permission
    async function requestMicrophonePermission() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        hasMicrophonePermission = true;
        permissionModal.style.display = 'none';
        // Start voice call after permission is granted
        if (isVoiceCallActive) {
          startVoiceCall();
        }
        return true;
      } catch (error) {
        console.error('Microphone access denied:', error);
        callScreenStatus.textContent = 'Microphone access denied';
        return false;
      }
    }
    // Initialize speech recognition
    function initSpeechRecognition() {
      if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
        alert('Speech recognition not supported in your browser. Try Chrome or Edge.');
        return null;
      }
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'ur-PK'; // Urdu language for voice calls
      recognition.onstart = () => {
        console.log('Voice recognition started');
        callScreenStatus.textContent = 'Listening...';
      };
      recognition.onresult = (event) => {
        if (isSpeaking) {
          console.log('Ignoring speech during bot speaking');
          return;
        }
        console.log('SpeechRecognition result received');
        let transcript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            transcript += event.results[i][0].transcript;
          }
        }
        if (transcript.trim() !== '') {
          console.log('Transcript:', transcript);
          // Add to transcript
          const transcriptElement = document.createElement('p');
          transcriptElement.className = 'user-transcript urdu-text';
          transcriptElement.textContent = `آپ: ${transcript}`;
          callScreenTranscript.appendChild(transcriptElement);
          callScreenTranscript.scrollTop = callScreenTranscript.scrollHeight;
          // Send the transcript to the chatbot
          processVoiceInput(transcript);
        }
      };
      recognition.onerror = (event) => {
        console.error('Speech recognition error', event.error);
        callScreenStatus.textContent = 'Error: ' + event.error;
        if (event.error === 'not-allowed') {
          permissionModal.style.display = 'flex';
        }
      };
      recognition.onend = () => {
        console.log('Speech recognition ended');
        if (isVoiceCallActive && !isSpeaking) {
          recognition.start();
        }
      };
      return recognition;
    }
    // Start voice call
    async function startVoiceCall() {
      // Set the flag that we're trying to start a voice call
      isVoiceCallActive = true;
      // Check if we already have permission
      if (!hasMicrophonePermission) {
        permissionModal.style.display = 'flex';
        return;
      }
      voiceCallScreen.classList.add('active');
      voiceCallBtn.classList.add('call-active');
      voiceCallStatus.classList.remove('hidden');
      callStartTime = new Date();
      callScreenStatus.textContent = 'Starting...';
      // Reset voice conversation history
      voiceConversationHistory = [];
      // Start timer
      callInterval = setInterval(updateCallTimer, 1000);
      // Start visualizer animation
      visualizerInterval = setInterval(animateVoiceVisualizer, 200);
      // Initialize speech recognition if not already done
      if (!recognition) {
        recognition = initSpeechRecognition();
      }
      if (recognition) {
        recognition.start();
      }
      // Speak welcome message
      speakMessage("السلام علیکم! میں آپ کا پی جی سی پائتھن ٹیوٹر ہوں۔ آپ پائتھن کے بارے میں کیا جاننا چاہتے ہیں؟");
    }
    // End voice call
    function endVoiceCall() {
      voiceCallScreen.classList.remove('active');
      isVoiceCallActive = false;
      voiceCallBtn.classList.remove('call-active');
      voiceCallStatus.classList.add('hidden');
      if (callInterval) clearInterval(callInterval);
      if (visualizerInterval) clearInterval(visualizerInterval);
      if (recognition) {
        recognition.stop();
      }
      console.log('Voice call ended');
    }
    // Process voice input
    function processVoiceInput(text) {
      // Show typing indicator in voice call UI
      const typingIndicator = document.createElement('p');
      typingIndicator.className = 'bot-transcript urdu-text';
      typingIndicator.innerHTML = '<span class="typing-indicator"><span></span><span></span><span></span></span>';
      callScreenTranscript.appendChild(typingIndicator);
      callScreenTranscript.scrollTop = callScreenTranscript.scrollHeight;
      // Process with AI
      getAIResponse(text, true) // true indicates voice call mode
        .then(botReply => {
          // Remove typing indicator
          typingIndicator.remove();
          // Add bot response to voice call UI
          const botResponseElement = document.createElement('p');
          botResponseElement.className = 'bot-transcript urdu-text';
          botResponseElement.textContent = `پائتھن ٹیوٹر: ${botReply}`;
          callScreenTranscript.appendChild(botResponseElement);
          callScreenTranscript.scrollTop = callScreenTranscript.scrollHeight;
          // Speak the response
          speakMessage(botReply);
        })
        .catch(error => {
          console.error('Error processing voice input:', error);
          // Remove typing indicator
          typingIndicator.remove();
          // Add error to voice call UI
          const errorElement = document.createElement('p');
          errorElement.className = 'bot-transcript urdu-text';
          errorElement.textContent = "پائتھن ٹیوٹر: معذرت، کچھ مسئلہ ہو گیا۔ براہ کرم دوبارہ کوشش کریں۔";
          callScreenTranscript.appendChild(errorElement);
          callScreenTranscript.scrollTop = callScreenTranscript.scrollHeight;
        });
    }
    // Speak message using Google TTS with Urdu support
    function speakMessage(text) {
      isSpeaking = true;
      callScreenStatus.textContent = 'Speaking...';
      // Stop recognition while speaking
      if (recognition) {
        recognition.stop();
      }
      // Create audio element
      const audio = new Audio();
      // Create a temporary div to handle RTL text
      const tempDiv = document.createElement('div');
      tempDiv.style.direction = 'rtl';
      tempDiv.style.fontFamily = "'Noto Nastaliq Urdu', serif";
      tempDiv.textContent = text;
      document.body.appendChild(tempDiv);
      // Get the text in correct reading order
      const correctedText = tempDiv.innerText;
      document.body.removeChild(tempDiv);
      // Encode text for URL
      const encodedText = encodeURIComponent(correctedText);
      // FIXED: Using CORS proxy to solve GitHub hosting issue
      const ttsUrl = `${GOOGLE_TTS_API}?ie=UTF-8&q=${encodedText}&tl=ur&client=tw-ob`;
      const proxyUrl = `${GOOGLE_TTS_PROXY}${encodeURIComponent(ttsUrl)}`;
      // Set audio source
      audio.src = proxyUrl;
      // Play audio
      audio.play()
        .then(() => {
          console.log('Playing Urdu audio via CORS proxy');
          // When audio finishes, set status back to listening
          audio.onended = () => {
            isSpeaking = false;
            callScreenStatus.textContent = 'Listening...';
            // Restart recognition after a short delay
            setTimeout(() => {
              if (isVoiceCallActive && recognition) {
                recognition.start();
              }
            }, 500);
          };
        })
        .catch(err => {
          console.error('Error playing audio:', err);
          callScreenStatus.textContent = 'Error playing audio';
          isSpeaking = false;
        });
    }
    // Enhanced typing effect function with formatting
    function typeMessage(element, message, onComplete) {
      if (currentTypingEffect) {
        clearInterval(currentTypingEffect);
      }
      element.innerHTML = '';
      const cursor = document.createElement('span');
      cursor.className = 'typing-cursor';
      element.appendChild(cursor);
      let i = 0;
      isTypingStopped = false;
      currentMessage = message;
      const stopBtn = document.createElement('div');
      stopBtn.className = 'stop-generation-btn';
      stopBtn.innerHTML = '<span class="material-icons">close</span>';
      stopBtn.onclick = () => {
        stopCurrentTyping();
        isTypingStopped = true;
        if (currentAbortController) {
          currentAbortController.abort();
          currentAbortController = null;
        }
      };
      element.parentElement.appendChild(stopBtn);
      let typingSpeed;
      if (message.length < 100) typingSpeed = 50;
      else if (message.length < 300) typingSpeed = 30;
      else typingSpeed = 10;
      currentTypingElement = element;
      currentBubble = element.parentElement;
      let isBold = false;
      let boldStart = -1;
      currentTypingEffect = setInterval(() => {
        if (i < message.length && !isTypingStopped) {
          // Check for bold markers
          if (message[i] === '*' && i+1 < message.length && message[i+1] === '*') {
            // Toggle bold state
            isBold = !isBold;
            i += 2; // Skip both asterisks
            return;
          }
          if (cursor.parentNode === element) {
            element.removeChild(cursor);
          }
          // Create character container
          const charContainer = document.createElement('span');
          // Add bold styling if needed
          if (isBold) {
            charContainer.classList.add('important-word');
          }
          // Add character
          charContainer.textContent = message[i];
          element.appendChild(charContainer);
          // Add cursor
          element.appendChild(cursor);
          i++;
          // Scroll only if user is near bottom
          scrollToBottomIfNeeded();
        } else {
          if (cursor.parentNode === element) {
            element.removeChild(cursor);
          }
          if (stopBtn.parentNode === element.parentElement) {
            element.parentElement.removeChild(stopBtn);
          }
          clearInterval(currentTypingEffect);
          currentTypingEffect = null;
          // Apply consistent formatting
          element.classList.add('formatted-response');
          if (onComplete) onComplete();
        }
      }, typingSpeed);
    }
    // Stop current typing effect
    function stopCurrentTyping() {
      if (currentTypingEffect) {
        clearInterval(currentTypingEffect);
        currentTypingEffect = null;
      }
      const stopBtn = currentBubble.querySelector('.stop-generation-btn');
      if (stopBtn) {
        stopBtn.remove();
      }
      const cursor = currentTypingElement.querySelector('.typing-cursor');
      if (cursor) {
        cursor.remove();
      }
      // Add the remaining text without typing effect
      let finalText = currentMessage;
      // Remove all ** markers
      finalText = finalText.replace(/\*\*/g, '');
      // Create a new container for the final text
      const finalContainer = document.createElement('div');
      finalContainer.innerHTML = finalText;
      // Replace the current content
      currentTypingElement.innerHTML = '';
      currentTypingElement.appendChild(finalContainer);
    }
    // Add message with typing effect and formatting
    function addMessageWithTyping(message, sender = "bot") {
      const bubble = document.createElement('div');
      bubble.className = `flex items-start space-x-3 message-appear ${sender === "user" ? "justify-end" : ""}`;
      if (sender === "bot") {
        bubble.innerHTML = `
          <div class="ai-icon p-2 rounded-full flex-shrink-0">
            <span class="material-icons text-white">smart_toy</span>
          </div>
          <div class="flex-1">
            <div class="chat-bubble-bot px-5 py-3 max-w-5xl">
              <div class="message-content"></div>
            </div>
          </div>`;
      } else {
        bubble.innerHTML = `
          <div class="flex-1 flex justify-end">
            <div class="chat-bubble-user px-5 py-3 max-w-5xl">
              <p class="text-sm font-medium">${message}</p>
            </div>
          </div>
          <div class="user-icon p-2 rounded-full flex-shrink-0">
            <span class="material-icons text-white">person</span>
          </div>`;
      }
      chatContainer.appendChild(bubble);
      scrollToBottomIfNeeded();
      if (sender === "bot") {
        const messageContent = bubble.querySelector('.message-content');
        typeMessage(messageContent, message);
      }
      return bubble;
    }
    // Regular add message (for user messages)
    function addMessage(message, sender = "bot") {
      const bubble = document.createElement('div');
      bubble.className = `flex items-start space-x-3 message-appear ${sender === "user" ? "justify-end" : ""}`;
      if (sender === "bot") {
        bubble.innerHTML = `
          <div class="ai-icon p-2 rounded-full flex-shrink-0">
            <span class="material-icons text-white">smart_toy</span>
          </div>
          <div class="flex-1">
            <div class="chat-bubble-bot px-5 py-3 max-w-3xl">
              <div class="formatted-response">${message}</div>
            </div>
          </div>`;
      } else {
        bubble.innerHTML = `
          <div class="flex-1 flex justify-end">
            <div class="chat-bubble-user px-5 py-3 max-w-3xl">
              <p class="text-sm font-medium">${message}</p>
            </div>
          </div>
          <div class="user-icon p-2 rounded-full flex-shrink-0">
            <span class="material-icons text-white">person</span>
          </div>`;
      }
      chatContainer.appendChild(bubble);
      scrollToBottomIfNeeded();
    }
    function showTypingIndicator() {
      const typingIndicator = document.createElement('div');
      typingIndicator.className = `flex items-start space-x-3 message-appear`;
      typingIndicator.innerHTML = `
        <div class="ai-icon p-2 rounded-full flex-shrink-0">
          <span class="material-icons text-white">smart_toy</span>
        </div>
        <div>
          <div class="chat-bubble-bot px-4 py-3 max-w-5xl">
            <div class="typing-indicator">
              <span></span>
              <span></span>
              <span></span>
            </div>
          </div>
        </div>`;
      chatContainer.appendChild(typingIndicator);
      scrollToBottomIfNeeded();
      return typingIndicator;
    }
    // Check if user is near bottom of chat
    function isNearBottom() {
      const threshold = 100; // pixels from bottom
      return chat.scrollHeight - chat.clientHeight <= chat.scrollTop + threshold;
    }
    // Scroll to bottom only if user is near bottom
    function scrollToBottomIfNeeded() {
      if (isNearBottom()) {
        chat.scrollTop = chat.scrollHeight;
      }
    }
    // --- IMAGE FEATURE FUNCTIONS ---
    // Handle image generation request using Together AI
    async function handleImageGeneration(prompt) {
        const typingIndicator = showTypingIndicator();
        apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(245, 158, 11, 0.5);"></span> <span>Generating Image...</span>';
        apiStatus.style.background = '#F59E0B';
        apiStatus.style.display = 'flex';
        try {
            const response = await fetch(TOGETHER_ENDPOINT, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${TOGETHER_API_KEY}`
                },
                body: JSON.stringify({
                    model: TOGETHER_MODEL,
                    prompt: prompt,
                    width: 512, // Reduced width
                    height: 512, // Reduced height
                    steps: 4 // Adjust steps as needed
                })
            });
            if (!response.ok) {
                const errorData = await response.json();
                console.error("Together AI Error:", errorData);
                throw new Error(`Image generation failed: ${errorData?.error?.message || 'Unknown error'}`);
            }
            const data = await response.json();
            const imageUrl = data.data[0]?.url; // Assuming the URL is in data[0].url
            typingIndicator.remove();
            if (imageUrl) {
                displayGeneratedImage(imageUrl);
                // Add to conversation history for context (as image URL)
                conversationHistory.push({ role: 'user', content: `Generated image for prompt: ${prompt}` });
                conversationHistory.push({ role: 'assistant', content: [{ type: "image_url", image_url: { url: imageUrl } }] });
            } else {
                throw new Error("Image URL not found in response");
            }
        } catch (error) {
            console.error('Error generating image:', error);
            typingIndicator.remove();
            addMessage(`Mujhe maaf karna, tasveer generate karte hue kuch masla ho gaya: ${error.message}`, "bot");
        } finally {
            apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.5);"></span> <span>AI Assistant Ready</span>';
            apiStatus.style.background = '#10B981';
        }
    }
    // Display generated image in chat with download functionality
    function displayGeneratedImage(imageUrl) {
        const bubble = document.createElement('div');
        bubble.className = `flex items-start space-x-3 message-appear`;
        bubble.innerHTML = `
          <div class="ai-icon p-2 rounded-full flex-shrink-0">
            <span class="material-icons text-white">smart_toy</span>
          </div>
          <div class="flex-1">
            <div class="chat-bubble-bot px-5 py-3 max-w-5xl">
                <div class="generated-image-container">
                    <img src="${imageUrl}" alt="Generated Image" class="generated-image">
                    <a href="${imageUrl}" download="generated_image.png" class="download-image-btn">Download Image</a>
                </div>
            </div>
          </div>`;
        chatContainer.appendChild(bubble);
        scrollToBottomIfNeeded();
        
        // Add event listener for download button
        const downloadBtn = bubble.querySelector('.download-image-btn');
        downloadBtn.addEventListener('click', (e) => {
            e.preventDefault(); // Prevent default link behavior
            downloadImage(imageUrl, 'generated_image.png');
        });
    }

    // Function to download image directly
    function downloadImage(url, filename) {
        fetch(url)
            .then(response => response.blob())
            .then(blob => {
                const blobUrl = window.URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = blobUrl;
                a.download = filename;
                document.body.appendChild(a);
                a.click();
                a.remove();
                window.URL.revokeObjectURL(blobUrl);
            })
            .catch(error => {
                console.error('Download failed:', error);
                // Fallback: open in new tab if download fails
                window.open(url, '_blank');
            });
    }

    // Handle image upload and prompt submission
    function handleImageUploadAndPrompt(prompt) {
        if (!uploadedImageBase64) {
            alert("Koi tasveer upload nahi ki gayi.");
            return;
        }
        if (!prompt.trim()) {
            alert("Barri mehrbani kar ke tasveer ke mutabiq sawal daalein.");
            return;
        }
        
        // Add user message (the prompt text) to chat
        addMessage(prompt, "user");

        // Show typing indicator and get AI response
        const typingIndicator = showTypingIndicator();
        
        // First, extract text from the image
        extractTextFromImage(uploadedImageBase64)
            .then(extractedText => {
                console.log("Extracted Text:", extractedText); // Log for debugging
                // Then, send the extracted text and user prompt to the main text model
                return getAIResponseForImageContext(extractedText, prompt);
            })
            .then(botReply => {
                typingIndicator.remove();
                addMessageWithTyping(botReply, "bot");
            })
            .catch(error => {
                console.error("Error analyzing image:", error);
                typingIndicator.remove();
                addMessage(`Mujhe maaf karna, tasveer ka jawab dene mein kuch masla ho gaya: ${error.message}`, "bot");
            })
            .finally(() => {
                // Clear input and preview state after submission
                userInput.value = '';
                uploadedImageBase64 = null;
                uploadedImagePreview = null;
            });
    }

    // New function to extract text from image using Qwen model
    async function extractTextFromImage(base64Image) {
        apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(245, 158, 11, 0.5);"></span> <span>Extracting Text from Image...</span>';
        apiStatus.style.background = '#F59E0B';
        apiStatus.style.display = 'flex';

        const payload = {
            model: OPENROUTER_IMAGE_MODEL,
            messages: [
                { role: 'system', content: "You are an expert OCR system. Extract all readable text from the provided image. Respond only with the extracted text, nothing else. If no text is found, respond with 'No text found in the image.'" },
                {
                    role: 'user',
                    content: [
                        { type: 'text', text: "Extract all text from this image." },
                        { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${base64Image}` } }
                    ]
                }
            ],
            max_tokens: 2000,
            temperature: 0.0, // For consistent OCR
            stream: false
        };

        try {
            const response = await fetch(OPENROUTER_IMAGE_ENDPOINT, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${OPENROUTER_IMAGE_API_KEY}`,
                    'HTTP-Referer': window.location.origin,
                    'X-Title': document.title
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                console.error("OpenRouter Image Analysis Error:", errorData);
                throw new Error(`Image analysis failed: ${errorData?.error?.message || 'Unknown error'}`);
            }

            const data = await response.json();
            const extractedText = data?.choices?.[0]?.message?.content?.trim() || "No text found in the image.";
            
            // Add to conversation history for context (only the extracted text)
            conversationHistory.push({ role: 'system', content: `[Image Context: ${extractedText}]` });
            
            return extractedText;
        } catch (error) {
            console.error('Error extracting text from image:', error);
            throw error;
        } finally {
            apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.5);"></span> <span>AI Assistant Ready</span>';
            apiStatus.style.background = '#10B981';
        }
    }

    // New function to get AI response using the extracted image context and user prompt with the main text model
    async function getAIResponseForImageContext(extractedText, userPrompt) {
        apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(245, 158, 11, 0.5);"></span> <span>Processing Image Context...</span>';
        apiStatus.style.background = '#F59E0B';
        apiStatus.style.display = 'flex';

        // Prepare the message for the main text model
        const imageContextMessage = `The user uploaded an image. Here is the text extracted from it: "${extractedText}". Now, please answer the user's question about this image.`;
        
        // Add the image context message to history for continuity
        conversationHistory.push({ role: 'user', content: imageContextMessage });
        conversationHistory.push({ role: 'assistant', content: "I have received the image context and will use it to answer your question." });

        // Now get the response for the user's actual prompt
        const payload = {
            model: OPENROUTER_TEXT_MODEL,
            messages: [
                { role: 'system', content: SYSTEM_PROMPT },
                ...conversationHistory,
                { role: 'user', content: userPrompt }
            ],
            max_tokens: 2000,
            temperature: 0.7,
            top_p: 0.9,
            stream: false
        };

        try {
            currentAbortController = new AbortController();
            const response = await fetch(OPENROUTER_TEXT_ENDPOINT, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${OPENROUTER_TEXT_API_KEY}`,
                    'HTTP-Referer': window.location.origin,
                    'X-Title': document.title
                },
                body: JSON.stringify(payload),
                signal: currentAbortController.signal
            });

            if (!response.ok) {
                const errorData = await response.json();
                console.error("OpenRouter Text Model Error:", errorData);
                throw new Error(`API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
            }

            const data = await response.json();
            const botReply = data?.choices?.[0]?.message?.content;

            if (!botReply) {
                throw new Error("Invalid response structure from AI model.");
            }

            // Add to conversation history
            conversationHistory.push({ role: 'user', content: userPrompt });
            conversationHistory.push({ role: 'assistant', content: botReply });

            return botReply;
        } catch (error) {
            console.error('Error getting AI response for image context:', error);
            throw error;
        } finally {
            apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.5);"></span> <span>AI Assistant Ready</span>';
            apiStatus.style.background = '#10B981';
            currentAbortController = null;
        }
    }

    // --- END IMAGE FEATURE FUNCTIONS ---
    // Encode image file to base64
    function encodeImageFile(file) {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = (event) => resolve(event.target.result.split(',')[1]); // Get base64 part
            reader.onerror = (error) => reject(error);
            reader.readAsDataURL(file);
        });
    }
    // AI Response Function with OpenRouter API Integration (for text)
    async function getAIResponse(message, isVoiceCall = false) {
      // Update API status indicator
      apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(245, 158, 11, 0.5);"></span> <span>Connecting to AI...</span>';
      apiStatus.style.background = '#F59E0B';
      apiStatus.style.display = 'flex';
      // Prepare the request payload for text
      const payload = {
        model: OPENROUTER_TEXT_MODEL, // Use the NEW text generation model
        messages: [
          { 
            role: 'system', 
            content: isVoiceCall ? VOICE_SYSTEM_PROMPT : SYSTEM_PROMPT 
          },
          ...(isVoiceCall ? voiceConversationHistory : conversationHistory),
          { role: 'user', content: message }
        ],
        max_tokens: isVoiceCall ? 500 : 4000, // Adjust max tokens for text
        temperature: 0.7,
        top_p: 0.9,
        stream: false
      };
      try {
        currentAbortController = new AbortController();
        const response = await fetch(OPENROUTER_TEXT_ENDPOINT, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${OPENROUTER_TEXT_API_KEY}`, // Use the NEW text API key
            'HTTP-Referer': window.location.origin,
            'X-Title': document.title
          },
          body: JSON.stringify(payload),
          signal: currentAbortController.signal
        });
        if (!response.ok) {
          const errorData = await response.json();
          console.error("OpenRouter Error:", errorData);
          throw new Error(`API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
        }
        const data = await response.json();
        const botReply = data.choices[0].message.content;
        // Add to conversation history
        if (isVoiceCall) {
          voiceConversationHistory.push({ role: 'user', content: message });
          voiceConversationHistory.push({ role: 'assistant', content: botReply });
        } else {
          conversationHistory.push({ role: 'user', content: message });
          conversationHistory.push({ role: 'assistant', content: botReply });
        }
        // Update API status indicator
        apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.5);"></span> <span>AI Assistant Ready</span>';
        apiStatus.style.background = '#10B981';
        return botReply;
      } catch (error) {
        console.error('Error getting AI response:', error);
        // Update API status indicator
        apiStatus.innerHTML = '<span style="width: 8px; height: 8px; border-radius: 50%; margin-right: 6px; background-color: white; box-shadow: 0 0 0 2px rgba(239, 68, 68, 0.5);"></span> <span>API Connection Error</span>';
        apiStatus.style.background = '#EF4444';
        throw error;
      }
    }
    async function sendMessage() {
      const text = userInput.value.trim();
      if (!text) return;
      // Check for /imagine command
      if (text.startsWith('/imagine ')) {
          const prompt = text.substring(9).trim(); // Remove '/imagine ' prefix
          if (!prompt) {
              alert("Barri mehrbani kar ke tasveer generate karne ke liye prompt daalein. Jaise: /imagine A beautiful landscape");
              return;
          }
          userInput.value = ''; // Clear input
          handleImageGeneration(prompt);
          return;
      }
      // Check if we are waiting for an image prompt
      if (uploadedImageBase64) {
          handleImageUploadAndPrompt(text);
          return;
      }
      // Stop any ongoing typing
      if (currentTypingEffect) {
        stopCurrentTyping();
      }
      addMessage(text, "user");
      userInput.value = "";
      userInput.focus();
      const typingIndicator = showTypingIndicator();
      try {
        const botReply = await getAIResponse(text);
        typingIndicator.remove();
        addMessageWithTyping(botReply, "bot");
      } catch (error) {
        console.error("Error:", error);
        typingIndicator.remove();
        if (error.name !== 'AbortError') {
          addMessage(`Mujhe maaf karna, kuch technical masla ho gaya: ${error.message}`, "bot");
        }
      } finally {
        currentAbortController = null;
      }
    }
    // Event listeners
    sendBtn.addEventListener('click', sendMessage);
    userInput.addEventListener('keypress', (e) => {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        sendMessage();
      }
    });
    // Auto-expand textarea for user input
    userInput.addEventListener('input', function() {
      this.style.height = 'auto';
      this.style.height = (this.scrollHeight) + 'px';
    });
    // Voice call functionality
    voiceCallBtn.addEventListener('click', () => {
      if (isVoiceCallActive) {
        endVoiceCall();
      } else {
        startVoiceCall();
      }
    });
    callScreenEndBtn.addEventListener('click', endVoiceCall);
    requestPermissionBtn.addEventListener('click', async () => {
      const permissionGranted = await requestMicrophonePermission();
      if (permissionGranted) {
        // Start voice call after permission is granted
        startVoiceCall();
      }
    });
    // --- IMAGE FEATURE EVENT LISTENERS ---
    // Toggle image feature menu
    imageFeatureBtn.addEventListener('click', () => {
        imageFeatureMenu.classList.toggle('active');
    });
    // Close menu if clicked outside
    document.addEventListener('click', (e) => {
        if (!imageFeatureBtn.contains(e.target) && !imageFeatureMenu.contains(e.target)) {
            imageFeatureMenu.classList.remove('active');
        }
    });
    // Handle Generate Image option click
    generateImageOption.addEventListener('click', () => {
        imageFeatureMenu.classList.remove('active');
        userInput.value = '/imagine ';
        userInput.focus();
        userInput.setSelectionRange(userInput.value.length, userInput.value.length); // Move cursor to end
    });
    // Handle Upload Image option click
    uploadImageOption.addEventListener('click', () => {
        imageFeatureMenu.classList.remove('active');
        imageUploadInput.click(); // Trigger file input
    });
    // Handle image file selection
    imageUploadInput.addEventListener('change', async (event) => {
        const file = event.target.files[0];
        if (!file) return;
        if (!file.type.startsWith('image/')) {
            alert("Barri mehrbani kar ke sirf tasveer (image) files select karein.");
            return;
        }
        try {
            uploadedImageBase64 = await encodeImageFile(file);
            const reader = new FileReader();
            reader.onload = (e) => {
                uploadedImagePreview = e.target.result;
                // Create a preview message in chat (but don't add to conversation history yet)
                const bubble = document.createElement('div');
                bubble.className = `flex items-start space-x-3 message-appear justify-end`;
                bubble.innerHTML = `
                  <div class="flex-1 flex justify-end">
                    <div class="chat-bubble-user px-5 py-3 max-w-5xl">
                      <div class="image-preview-container">
                        <img src="${uploadedImagePreview}" alt="Uploaded Image Preview" class="image-preview">
                        <input type="text" class="image-prompt-input" placeholder="Tasveer ke mutabiq sawal daalein...">
                        <button class="image-prompt-submit">Submit</button>
                      </div>
                    </div>
                  </div>
                  <div class="user-icon p-2 rounded-full flex-shrink-0">
                    <span class="material-icons text-white">person</span>
                  </div>`;
                chatContainer.appendChild(bubble);
                scrollToBottomIfNeeded();
                
                // Make sure the input field is visible
                const promptInput = bubble.querySelector('.image-prompt-input');
                const submitBtn = bubble.querySelector('.image-prompt-submit');
                
                // Focus the input field after a short delay to ensure it's rendered
                setTimeout(() => {
                    promptInput.focus();
                }, 100);
                
                // Handle prompt submission for the uploaded image
                submitBtn.addEventListener('click', () => {
                    const prompt = promptInput.value.trim();
                    if (prompt) {
                        handleImageUploadAndPrompt(prompt);
                    } else {
                        alert("Barri mehrbani kar ke sawal daalein.");
                    }
                });
                promptInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter') {
                        e.preventDefault();
                        const prompt = promptInput.value.trim();
                        if (prompt) {
                            handleImageUploadAndPrompt(prompt);
                        } else {
                            alert("Barri mehrbani kar ke sawal daalein.");
                        }
                    }
                });
            };
            reader.readAsDataURL(file);
            userInput.value = ''; // Clear main input
        } catch (error) {
            console.error('Error encoding image:', error);
            alert("Tasveer upload karte hue kuch masla ho gaya.");
        }
    });
    // --- END IMAGE FEATURE EVENT LISTENERS ---
    // Start chat button handler
    startChatBtn.addEventListener('click', async () => {
      userName = userNameInput.value.trim();
      if (!userName) {
        alert("Please enter your name to continue");
        return;
      }
      // Hide modal and show chat interface
      nameModal.style.display = 'none';
      header.style.display = 'flex';
      chat.style.display = 'block';
      footer.style.display = 'block';
      apiStatus.style.display = 'flex';
      
      // Create welcome cards dynamically
      const welcomeCards = `
        <div class="message-appear flex justify-center mb-8">
          <div class="max-w-6xl w-full text-center">
            <div class="gradient-bg p-1 rounded-full inline-flex mb-4">
              <div class="bg-white p-2 rounded-full">
                <span class="material-icons" style="background: linear-gradient(135deg, #2563EB, #0EA5E9); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">code</span>
              </div>
            </div>
            <h2 class="welcome-title text-2xl font-bold mb-2">Assalam-o-Alaikum ${userName}! Mein PGC Python Tutor 4.2 hoon</h2>
            <p class="welcome-subtitle text-gray-700">Aap ka Python learning assistant. Roman Urdu mein Python programming seekhiye!</p>
            <div class="mt-6 grid grid-cols-1 sm:grid-cols-2 gap-3 max-w-md mx-auto">
              <div class="prompt-card rounded-xl p-4 text-sm cursor-pointer">
                <div class="flex items-center">
                  <div class="bg-blue-100 p-1 rounded-lg mr-2">
                    <span class="material-icons text-blue-600 text-sm">code</span>
                  </div>
                  <span class="font-semibold text-gray-800">Variable kya hota hai?</span>
                </div>
              </div>
              <div class="prompt-card rounded-xl p-4 text-sm cursor-pointer">
                <div class="flex items-center">
                  <div class="bg-purple-100 p-1 rounded-lg mr-2">
                    <span class="material-icons text-purple-600 text-sm">loop</span>
                  </div>
                  <span class="font-semibold text-gray-800">For loop kaise kaam karta hai?</span>
                </div>
              </div>
              <div class="prompt-card rounded-xl p-4 text-sm cursor-pointer">
                <div class="flex items-center">
                  <div class="bg-green-100 p-1 rounded-lg mr-2">
                    <span class="material-icons text-green-600 text-sm">functions</span>
                  </div>
                  <span class="font-semibold text-gray-800">Function kya hota hai?</span>
                </div>
              </div>
              <div class="prompt-card rounded-xl p-4 text-sm cursor-pointer">
                <div class="flex items-center">
                  <div class="bg-cyan-100 p-1 rounded-lg mr-2">
                    <span class="material-icons text-cyan-600 text-sm">list</span>
                  </div>
                  <span class="font-semibold text-gray-800">List kya hoti hai?</span>
                </div>
              </div>
            </div>
          </div>
        </div>
      `;
      chatContainer.innerHTML = welcomeCards;
      // Re-attach event listeners to the newly created prompt cards
      document.querySelectorAll('.prompt-card').forEach((prompt, index) => {
        prompt.addEventListener('click', () => {
          const prompts = [
            "Variable kya hota hai?",
            "For loop kaise kaam karta hai?",
            "Function kya hota hai?",
            "List kya hoti hai?"
          ];
          userInput.value = prompts[index];
          sendMessage();
        });
      });
      
      // --- MODIFICATION 2: Real Greeting from AI ---
      // Add personalized welcome message from AI
      setTimeout(async () => {
        // Show typing indicator while waiting for AI
        const typingIndicator = showTypingIndicator();
        try {
            // Get AI-generated greeting
            const aiGreeting = await getAIResponse(`Salam ${userName}! Aap beginner hain ya pro?`);
            typingIndicator.remove();
            addMessageWithTyping(aiGreeting, "bot");
            // Update system prompt context
            conversationHistory.push({ role: 'system', content: `User's name is ${userName}.` });
        } catch (error) {
            console.error("Error getting AI greeting:", error);
            typingIndicator.remove();
            const fallbackGreeting = `Assalam-o-Alaikum ${userName}! Mein PGC Python Tutor 4.2 hoon. Roman Urdu mein Python programming sikhane mein aap ki madad karoon ga. Kya aap beginner hain ya pro?`;
            addMessageWithTyping(fallbackGreeting, "bot");
            conversationHistory.push({ role: 'system', content: `User's name is ${userName}.` });
        }
      }, 500); // Slight delay for better UX
    });
    // Focus on input when modal is shown
    userNameInput.focus();
    // Check if we have microphone permission
    if (navigator.permissions) {
      navigator.permissions.query({name: 'microphone'}).then(permissionStatus => {
        hasMicrophonePermission = permissionStatus.state === 'granted';
        permissionStatus.onchange = () => {
          hasMicrophonePermission = permissionStatus.state === 'granted';
        };
      });
    }
  </script>
</body>
</html>
```
